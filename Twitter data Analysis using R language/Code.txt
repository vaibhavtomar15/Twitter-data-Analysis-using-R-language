require(twitteR)
require(RCurl)

consumer_key <- 'nZFwElAdKch4MIfsVHOpJbzco'
consumer_secret <- 'PP6IPNmvi3GotZp8p8sWcY0gqj4B5wbtbkjxDpY2HqXKSgXrja'
access_token <- '749654891761577984-UOtyJzb5vl2ZPFiJpos7Pu9IL02cvEx'
access_secret <- 'rrRxxyFSUPnalusgDt4xRU0beGR2XHQp1K9vM8cAekRhO'

setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)

#Extract Tweets
yogi.tweets = searchTwitter("YogiAdityanath", lang="en", resultType="recent")

#Convert it to Dataframe
df <- do.call("rbind",lapply(yogi.tweets, as.data.frame))

#Remove emoticonsdf$text <- sapply(df$text, function(row) iconv(row,"latin1", "ASCII", sub=""))

#remove URL's
df$text = gsub("(f|ht)tp(s?)://(.*)[.][a-z]+","",df$text)
sample <- df$text

#Add positive and negative word collection
pos.words = scan("positivewords.txt",what='character',comment.char=';')
neg.words = scan("negativewords.txt",what='character',comment.char=';')

#Add more words into postive and negative words
pos.words = c(pos.words, 'Congrats', 'prizes')
neg.words = c(neg.words, 'Fight', 'not', 'no')

score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
	require(plyr)
	require(stringr)
	list=lapply(sentences, function(sentence, pos.words, neg.words)
	{
		sentence = gsub('[[:punct:]]',' ',sentence)
		sentence = gsub('[[:cntrl:]]','',sentence)
		sentence = gsub('\\d+','',sentence)  #removes decimal number
		sentence = gsub('\n','',sentence)    #removes new lines
		sentence = tolower(sentence)
		word.list = str_split(sentence, '\\s+')
		words = unlist(word.list)  #changes a list to character vector
		pos.matches = match(words, pos.words)
		neg.matches = match(words, neg.words)
		pos.matches = !is.na(pos.matches)
		neg.matches = !is.na(neg.matches)
		pp = sum(pos.matches)
		nn = sum(neg.matches)
		score = sum(pos.matches) - sum(neg.matches)
		list1 = c(score, pp, nn)
		return (list1)
	}, pos.words, neg.words)
	score_new = lapply(list, `[[`, 1)
	pp1 = lapply(list, `[[`, 2)
	nn1 = lapply(list, `[[`, 3)

	scores.df = data.frame(score = score_new, text=sentences)
	positive.df = data.frame(Positive = pp1, text=sentences)
	negative.df = data.frame(Negative = nn1, text=sentences)

	list_df = list(scores.df, positive.df, negative.df)
	return(list_df)
}

# Clean the tweets and returns merged data frame
result = score.sentiment(sample, pos.words, neg.words)

library(reshape)
test1=result[[1]]
test2=result[[2]]
test3=result[[3]]

#Creating three different data frames for Score, Positive and Negative
#Removing text column from data frame
test1$text=NULL
test2$text=NULL
test3$text=NULL
#Storing the first row(Containing the sentiment scores) in variable q
q1=test1[1,]
q2=test2[1,]
q3=test3[1,]
qq1=melt(q1, ,var='Score')
qq2=melt(q2, ,var='Positive')
qq3=melt(q3, ,var='Negative') 
qq1['Score'] = NULL
qq2['Positive'] = NULL
qq3['Negative'] = NULL
#Creating data frame
table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)

#Merging three data frames into one
table_final=data.frame(Text=table1$Text, Score=table1$value, Positive=table2$value, Negative=table3$value)

#Positive Percentage

#Renaming
posSc=table_final$Positive
negSc=table_final$Negative

#Adding column
table_final$PosPercent = posSc/ (posSc+negSc)

#Replacing Nan with zero
pp = table_final$PosPercent
pp[is.nan(pp)] <- 0
table_final$PosPercent = pp

#Negative Percentage

#Adding column
table_final$NegPercent = negSc/ (posSc+negSc)

#Replacing Nan with zero
nn = table_final$NegPercent
nn[is.nan(nn)] <- 0
table_final$NegPercent = nn

#Histogram
hist(table_final$Positive, col=rainbow(10))
hist(table_final$Negative, col=rainbow(10))
hist(table_final$Score, col=rainbow(10))

#Pie
slices <- c(sum(table_final$Positive), sum(table_final$Negative))
labels <- c("Positive", "Negative")
library(plotrix)
pie(slices, labels = labels, col=rainbow(length(labels)), main="Sentiment Analysis")
pie3D(slices, labels = labels, col=rainbow(length(labels)),explode=0.00, main="Sentiment Analysis")

yogi_text = sapply(yogi.tweets, function(x) x$getText())
 #sapply returns a vector 
df <- do.call("rbind", lapply(yogi.tweets, as.data.frame))
 #lapply returns a list
yogi_text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
str(yogi_text)
 #gives the summary/internal structure of an R object

library(tm) 
#tm: text mining
yogi_corpus <- Corpus(VectorSource(yogi_text))
 #corpus is a collection of text documents
yogi_corpus
inspect(yogi_corpus[1])



trump_text = sapply(trump.tweets, function(x) x$getText())
 #sapply returns a vector 
df <- do.call("rbind", lapply(trump.tweets, as.data.frame))
 #lapply returns a list
trump_text <- sapply(df$text,function(row) iconv(row, "latin1", "ASCII", sub=""))
str(trump_text)
 #gives the summary/internal structure of an R object

library(tm) 
#tm: text mining
trump_corpus <- Corpus(VectorSource(trump_text))
 #corpus is a collection of text documents
trump_corpus
inspect(trump_corpus[1])

s
#clean text
library(wordcloud)
trump_clean <- tm_map(yogi_corpus, removePunctuation)
trump_clean <- tm_map(yogi_clean, removeWords, c('the','this','is','a','an', stopwords("english")))
#trump_clean <- tm_map(yogi_clean, stemDocument)
trump_clean <- tm_map(yogi_clean, removeNumbers)
trump_clean <- tm_map(yogi_clean, stripWhitespace)
wordcloud(yogi_clean, random.order=F,max.words=80, col=rainbow(50), scale=c(3.5,1))

